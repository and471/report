\documentclass[a4paper]{article}

\usepackage{parskip}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{float}
\usepackage[justification=centering]{caption}


\begin{document}

\title{Product Management, Feedback and Evaluation}
\author{Andrew Higginson \and Bryan Liu \and Jia Guang Choo \and Emma Hulme \and 
Timothy van Bremen \and Thomas Taylor-Hall}
\date{\today}
\maketitle

\setcounter{table}{0}
\linespread{1.15}

\section{Project Introduction}
As part of the renovation of the William Penney Building on the Sherfield 
walkway, interactive screens are to be installed. Mounted inside the building,
four projectors will simultaneously display content onto floor to ceiling glass
panels that are visible to passers-by. Also, an 84-inch 4K resolution touch 
screen is to be mounted by the entrance doors. 

Our project consists of developing an ``App Store" for uploading interactive 
content and visualisations to be displayed on the four projected screens. 
Administrators will also be able to use this system to moderate and schedule 
content. Finally, we will be developing a playout system to show the content 
on multiple screens in multiple resolutions.

\section{Relationships and Feedback}
Early on we identified that the main stakeholder in our project is our supervisor David. The core of our project is the scheduling component, which he would operate as an administrator, and so his opinion of the overall design of the project was critical. We also identified our second class of stakeholder, those who browse the visualisation catalogue and submit visualisations and adverts. Their stake is relatively large as without their full engagement and satisfaction, the variety of content being shown will remain small. Finally those see the visualisations being played out. Whilst this final set of users are important, their stake is relatively small, in that all they need to see is the content being played out successfully.

Our relationship with our supervisor David has consisted of weekly 
meetings, and emails if appropriate. Finally, we explain what features are in progress/to be done over the next week so David is 
always kept in the loop.

\begin{figure}[H]
  \begin{minipage}{0.49\textwidth}
    \includegraphics[width = \textwidth, trim = 0 2cm 0 7cm, clip]{./evaluation/meeting-board2.jpg}
  \end{minipage}
  \begin{minipage}{0.49\textwidth}
    \includegraphics[width = \textwidth, trim = 1.2cm 1.5cm 1.2cm 2.5cm, clip]{./evaluation/meeting-board.jpg}
  \end{minipage}
  \caption{Meeting notes showing feedback from David (our supervisor) and group progress \\
                    after sprint cycles 2 (left) and 4 (right).}
  \label{fig:meetingboard}
\end{figure}

We have also received some representative model data to seed our database, 
instead of using dummy data. This was provided by David and will also be 
used to test submission, moderation and display features of our system.

For example, after we showed David mockups of the scheduling screen, he said that 
he wanted priorities associated with each visualisation to be shown. We agreed as a 
group that this would be easy to implement, and assigned the task to an appropriate
group member on Trello. 


\section{Product Requirement, Value \& Impact}
In the first week of beginning our project, we met with our supervisor 
David to draw out the initial components. Initially, these were general
requirements that we divided into user, admin and interface 
requirements. We later sent these requirements to David so he could check
they were satisfactory and have them for his records. He was happy with 
these and did not modify them.



\begin{figure}[H]
  \centering
    \includegraphics[width = 0.5\textwidth]{./evaluation/specs.png}

  \caption{Initial specifications on shared repository.}
  \label{fig:specs}
\end{figure}

\subsection{Value Proposition}
\begin{figure}[H]
   \begin{center}
      \includegraphics[width = 0.99\textwidth, trim = 1cm 6.5cm 1cm 4.5cm, clip]{./evaluation/value_prop_canvas.jpg}

   \end{center}
\end{figure}



\section{Task Management}
In the coming weeks, we then clarified and expanded these requirements as 
a group. This allowed us to discuss implementation and technical details
of specific features.


During development, we are constantly looking at the requirements for all of our stakeholders, which 
we have stored in a shared document. In our weekly scrums, we have 
presented the work we have done and discuss whether the project is on the 
right track. In our discussions, David has refined how he wants our
scheduling algorithm to schedule visualisations for a particular time. 



We have been prioritising tasks using our Trello board with different
columns. In addition to this, we have been constantly communication both 
in person and online, to make sure members are implementing assigned tasks
in appropriate times. We have been actively encouraging use of the Trello 
board to update the group when tasks have been completed. This way, 
we don't have to constantly ask or look at code to see if a feature has 
been implemented. If appropriate, group members working on the backend
have been using an internal wiki on gitlab to provide information about
routing, controller actions and parameters. 


\begin{figure}[H]
  \centering
    \includegraphics[width = 0.5\textwidth]{./evaluation/trello-columns.png}

  \caption{Priority columns on our Trello board.}
  \label{fig:columns}
\end{figure}


\begin{figure}[H]
  \centering
    \includegraphics[width = 0.5\textwidth]{./evaluation/trello-due-date.png}

  \caption{Setting a due date for a particular task.}
  \label{fig:deadline}
\end{figure}




\subsection{Story Splitting}




\subsection{Spikes - Experiments with new technologies}




\section{Building the right thing - Assumption Validation}
Given the tight time constraints for the entire project, we agreed to collect
user feedback as soon as the project commences. This ensures the team
is building the right thing which our client needs.


\subsection{User interface mockups}
A release cycle in our project generally takes the following form. Before implementing a particular part of our project, we begin with creating mockups (figure \ref{fig:mockup}). These are relatively quick to produce and allow us to quickly think through the design of our project, with being tied down to any implementation details which would affect our thinking. After completion, we then show the mockups to the main stakeholder in the project, our supervisor David, who gives us feedback/changes. Once a general design is settled on, within that week's sprint cycle, we complete the main implementation of the UI, but only do so up to the point of it being useful to show how it would be used. It is not yet interfacing with the backend, and hence small changes at this point are simple to do, with the following week's sprint cycle involving 'hooking' up this UI prototype and our backend.\\

We also make sure that this prototype is in some way, seeded with some dummy/representative data, so that it is clear how each part of the project will operate in practice.\\

This way of working allows us to 'pivot' many times, and with minimal overhead of reimplementation, as it allows us to identify problems, or learn more about the issue we are trying to solve, before we write large volumes of code which may end up to be not useful. The fact that we have this lean approach also \textbf{encourages us} to pivot more often, as there is no reason not to do so.

For example, after we showed David mockups of the scheduling screen, he said that 
he wanted priorities associated with each visualisation to be shown. We agreed as a 
group that this would be easy to implement, and assigned the task to an appropriate
group member on Trello.  %TODO: edit

\begin{figure}[H]
   \begin{center}
      \includegraphics[width = \textwidth, trim = 0 0 0 0cm, clip]{./evaluation/mockup.png}
   \end{center}
   \caption{Mockups on User Interface}
   \label{fig:mockup}
\end{figure}

\subsection{Requirements on intangible ideas}
Compared to User Interfaces which user can see and feel, we believe 
uncovering the client's assumption on playout scheduling via mockups or 
prototypes would not be feasible as the algorithm is mainly rule-based.
We instead deliver our ideas with illustrations on whiteboard and
capture feedback from our supervisor.

Throughout discussions we have uncovered several assumptions, with one of them
expecting the scheduling algorithm to ensure playout time is 
directly proportional to metric set by administrators. In response,
we have created additional unit tests to incorporate such requirements 
in our scheduling algorithm.

\begin{figure}[H]
  \begin{minipage}{0.46\textwidth}
      \includegraphics[width = 0.99\textwidth, trim = 0 4.5cm 0 7cm, clip]{./evaluation/scheduling_whiteboard.jpg}
  \end{minipage}
  \begin{minipage}{0.53\textwidth}
      \includegraphics[width = 0.99\textwidth]{./evaluation/scheduling_spec.png}
  \end{minipage}
  \caption{Capturing scheduling requirements on whiteboard (left)\\ and subsequently via RSpec unit tests (right)}
 
\end{figure}

\subsection{User testing}
We have also conducted implicit user tests during demonstrations of new features,
where we ask our supervisor to conduct a task with minimal instruction and guidance
(e.g. to navigate to the visualisation scheduling page and schedule some visualistions
for playout).

Such testing allows us to learn what are obvious to us but obscure to users.
For example, in one of our demonstrations we observed that our supervior 
took slightly longer than we expected and had multiple pauses when
being asked to navigate to the visualisation moderation and scheduling pages. This 
indicates the icon to show the user menu might not be evident to users and
description for menu items might not be clear enough. Based on such observations
we have changed the size of the ``show menu" button, as well as explored the effect
of different link colours on user menu.

We are planning to extend the user to test to cover more users, including staff
and students who would potentially use the platform to submit and view visualisations, the second in our list of stakeholders.

\section{Evaluation of Project}
%How will we evaluate?
As a group, we are constantly evaluating our project by testing after a 
feature is implemented. We make use of both RSpec and manual testing. In 
addition, our project progress is evaluated by David in our weekly 
meetings. Using Jenkins for Continuous Integration, we have given David
the address of our ``release vm'', where he can see the latest working 
version of the project. From this, David can constantly evaluate our project 
through all stages of development.

Quantitively, we can evaluate our project by ticking off our intial 
requirements. Also, we will use the systems ourselves, both from the user 
and administrator perspective, to evaluate the project from both our stakeholders.
This will include uploading of visualisations and viewing other visualisations as a
user, and moderating and scheduling visualisations as an admin.

Using our Trello board and version control, we can see which features have been 
implemented by which group member. To improve our teamwork for future group 
projects, we will sit down as a group and describe our strengths and weaknesses in 
this project.

TODO: get externals to evaluate, people from data science institute? 

TODO: stuff from eval lecture





\end{document}
